# 分割网络简介

[toc]

## UNet及其衍生

UNet是一种经典的图像分割网络，主要范围三部分：下采样（编码器），上采样（解码器）和skip connection组层，拓扑结构如下

![image-20230824173832592](/Users/blackcat/北大实习/分割网络简介.assets/image-20230824173832592.png)

> 关注论文所传递的大方向，不要被论文中的细节局限了创造力.至于网络多深好，参数怎么调，特征提取器怎么选择，这些都是些鸡毛蒜皮的小事

> 降采样的意义:可以增加对输入图像的一些小扰动的鲁棒性，比如图像平移，旋转等，减少过拟合的风险，降低运算量，和增加感受野的大小。浅层采样得到的是颜色，边界这种信息，而深层的信息因为感受野大了，得到了玄学的东西
>
> 升采样的最大的作用其实就是把抽象的特征再还原解码到原图的尺寸，最终得到分割结果。

![img](https://pic1.zhimg.com/80/v2-b70bb7e451954a0c88accaf5da36f2d4_1440w.webp)

至于为什么选择了4层，这个其实就是根据数据集的不同调试出来的，不同层次的特征对于不同的数据集具有不同的意义，并不是说我设计一个4层的U-Net，就像原论文给出的那个结构，就一定对所有数据集的分割问题都最优。关键就在于怎么样使用不同深度的特征结构。

### UNet++

![img](https://pic4.zhimg.com/80/v2-8b76a55017c4cb60270880d9ac58b1a3_1440w.webp)

这样的设计结构，包含了1~4层unet,这个结构的好处就是我不管你哪个深度的特征有效，我干脆都给你用上，让网络自己去学习不同深度的特征的重要性.并且他只有一个特征提取器，也就是encoder过程

当然，因为没有连接，所以这个网络无法训练，我们可以改成下面这样![image-20230824175207701](/Users/blackcat/北大实习/分割网络简介.assets/image-20230824175207701.png)

emm很好，不过这样子就没有了长连接，U-Net中的长连接是有必要的，它联系了输入图像的很多信息，有助于还原降采样所带来的信息损失.为了综合长连接和短连接，我们提出了这样的网络。。![img](https://pic1.zhimg.com/80/v2-36e3f4c3342bf872fd5fcb8186f91c5c_1440w.webp)

#### 深度监督

当然，仅仅只有上面的这个网络形状其实有个问题，因为中间部分在反向传播的时候无法接受梯度。一个解决方式就是深监督,具体操作就是在最顶上的每个输出层后面都加一个1*1卷积核，监督每个分支U-Net的输出![img](https://pic2.zhimg.com/80/v2-debfd1acf4b9f2a63eea5db0fe920ef5_1440w.webp)

使用了深监督，我们就可以**剪枝**！因为在深监督的过程中，每个子网络的输出都其实已经是图像的分割结果了，所以如果小的子网络的输出结果已经足够好了，我们可以随意的剪掉那些多余的部分了。所以我们在测试的时候就可以剪掉不需要的枝叶，但是训练的时候不能减掉，因为他会辅助其它层训练。![img](https://pic1.zhimg.com/80/v2-62f88a068a51c718b18d9bd2fb0697b4_1440w.webp)

通过训练完的模型进行剪枝之后的对比，我们可以直观的选择合适的深度的Unet，比如这里我们可以选择深度为2从而减少参数量。



```python

class UnetBlock(nn.Module):
    def __init__(self, inChannel, outChannel) -> None:
        #使用卷积核大小3，步长1，填充1，保持大小不变，从而让神经网络绝对对称
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(inChannel, outChannel, 3, padding=1,stride=1),
            nn.BatchNorm2d(outChannel),
            nn.ReLU(),
            nn.Conv2d(outChannel, outChannel, 3, padding=1,stride=1),
            nn.BatchNorm2d(outChannel),
            nn.ReLU(),
        )

    def forward(self, x):
        x = self.net(x)
        return x



class UNetPP(nn.Module):
    def __init__(self, inChannel,outChannel) -> None:
        super().__init__()
        ch = [32, 64, 128, 256, 512]
        # 一个池化层
        self.pool = nn.MaxPool2d(stride=2, kernel_size=2)
        # 两层加起来要求层数不变而大小相同
        self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=True)


        self.x0_0 = UnetBlock(inChannel, ch[0])
        self.x1_0 = UnetBlock(ch[0], ch[1])
        self.x2_0 = UnetBlock(ch[1], ch[2])
        self.x3_0 = UnetBlock(ch[2], ch[3])
        self.x4_0 = UnetBlock(ch[3], ch[4])
        self.x0_1 = UnetBlock(ch[0] + ch[1], ch[0])
        self.x1_1 = UnetBlock(ch[1] + ch[2], ch[1])
        self.x2_1 = UnetBlock(ch[2] + ch[3], ch[2])
        self.x3_1 = UnetBlock(ch[3] + ch[4], ch[3])

        self.x0_2 = UnetBlock(ch[0] + ch[1] + ch[0], ch[0])
        self.x1_2 = UnetBlock(ch[1] + ch[2] + ch[1], ch[1])
        self.x2_2 = UnetBlock(ch[2] + ch[3] + ch[2], ch[2])

        self.x0_3 = UnetBlock(ch[0] + ch[1] + ch[0] + ch[0], ch[0])
        self.x1_3 = UnetBlock(ch[1] + ch[2] + ch[1] + ch[1], ch[1])

        self.x0_4 = UnetBlock(ch[0] + ch[1] + ch[0] + ch[0] + ch[0], ch[0])

        # 最后使用深度监督final层输出结果
        self.final1 = nn.Conv2d(ch[0], outChannel, 1)
        self.final2 = nn.Conv2d(ch[0], outChannel, 1)
        self.final3 = nn.Conv2d(ch[0], outChannel, 1)
        self.final4 = nn.Conv2d(ch[0], outChannel, 1)
    def forward(self, x):
        x0_0 = self.x0_0(x)
        x = self.pool(x0_0)
        x1_0 = self.x1_0(x)
        x = self.pool(x1_0)
        x2_0 = self.x2_0(x)
        x = self.pool(x2_0)
        x3_0 = self.x3_0(x)
        x = self.pool(x3_0)
        x4_0 = self.x4_0(x)
        # 第一轮下降结束
        # 计算后续结果
        x0_1 = self.x0_1(torch.cat([x0_0, self.up(x1_0)], dim=1))#在深度上累加
        x1_1 = self.x1_1(torch.cat([x1_0, self.up(x2_0)], dim=1))
        x2_1 = self.x2_1(torch.cat([x2_0, self.up(x3_0)], dim=1))
        x3_1 = self.x3_1(torch.cat([x3_0, self.up(x4_0)], dim=1))

        x0_2 = self.x0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], dim=1))
        x1_2 = self.x1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], dim=1))
        x2_2 = self.x2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], dim=1))

        x0_3 = self.x0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], dim=1))
        x1_3 = self.x1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], dim=1))

        x0_4 = self.x0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], dim=1))

        output1 = self.final1(x0_1)
        output2 = self.final2(x0_2)
        output3 = self.final3(x0_3)
        output4 = self.final4(x0_4)
        return [output1, output2, output3, output4]

```





















